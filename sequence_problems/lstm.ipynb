{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29bee5c2",
   "metadata": {},
   "source": [
    "## Uni directional LSTM : with batch_first = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34a7ff38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1735,  0.0038,  0.1194,  0.1309, -0.0380, -0.0148, -0.0819,\n",
      "          -0.0277,  0.0496,  0.0536,  0.1000, -0.0668,  0.1009,  0.0773,\n",
      "           0.0688, -0.0478,  0.1195, -0.0588,  0.0189, -0.0175],\n",
      "         [-0.1130,  0.0776,  0.0244,  0.0391,  0.0204, -0.0470, -0.0093,\n",
      "          -0.1353,  0.0512,  0.1718,  0.2299,  0.1731,  0.0400, -0.0017,\n",
      "          -0.0147,  0.0133,  0.3188, -0.0916, -0.0131, -0.0774]],\n",
      "\n",
      "        [[ 0.0812,  0.0455,  0.0047,  0.1378,  0.0083,  0.0119, -0.1008,\n",
      "           0.1060,  0.2122, -0.0591,  0.2257, -0.1863,  0.0897, -0.0348,\n",
      "           0.0083,  0.1045,  0.1123, -0.0628,  0.0725,  0.0522],\n",
      "         [ 0.1395,  0.1696, -0.1172, -0.0369,  0.0646,  0.1543,  0.0258,\n",
      "           0.1252,  0.2361,  0.1940,  0.0922, -0.0354,  0.0168,  0.0974,\n",
      "          -0.1142, -0.1370,  0.0984,  0.0826, -0.0957,  0.1414]],\n",
      "\n",
      "        [[ 0.0641,  0.1497, -0.0913, -0.0074,  0.0141, -0.0551, -0.0394,\n",
      "           0.1378,  0.0189,  0.0119,  0.0033, -0.0797,  0.0029, -0.1228,\n",
      "          -0.1744, -0.0622,  0.1366, -0.0503,  0.0833, -0.1936],\n",
      "         [ 0.0835,  0.1460, -0.1632, -0.0009, -0.1080,  0.0853,  0.1047,\n",
      "           0.1883,  0.0468,  0.2327,  0.1032, -0.0724,  0.0418,  0.1980,\n",
      "          -0.1232, -0.1628,  0.1094,  0.0797, -0.0712,  0.1553]]],\n",
      "       grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(13)\n",
    "lstm_input = torch.randn(2, 3, 10)\n",
    "\n",
    "# Reshape the input tensor\n",
    "reshaped_input = lstm_input.permute(1, 0, 2)  # (sequence_length, batch_size, input_dim)\n",
    "\n",
    "# Define the LSTM cell\n",
    "input_dim = 10  # Number of features at each time step\n",
    "hidden_dim = 20  # Number of hidden units in the LSTM cell\n",
    "lstm_cell = nn.LSTMCell(input_dim, hidden_dim)\n",
    "\n",
    "# Initialize the hidden state and cell state\n",
    "batch_size = 2\n",
    "hx = torch.zeros(batch_size, hidden_dim)\n",
    "cx = torch.zeros(batch_size, hidden_dim)\n",
    "\n",
    "# Pass the reshaped input through the LSTM cell\n",
    "output = []\n",
    "for i in range(3):  # Iterate over the sequence length\n",
    "    hx, cx = lstm_cell(reshaped_input[i], (hx, cx))\n",
    "    output.append(hx)\n",
    "\n",
    "# Convert the output to a tensor\n",
    "output = torch.stack(output)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e61df9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0641,  0.1497, -0.0913, -0.0074,  0.0141, -0.0551, -0.0394,  0.1378,\n",
       "          0.0189,  0.0119,  0.0033, -0.0797,  0.0029, -0.1228, -0.1744, -0.0622,\n",
       "          0.1366, -0.0503,  0.0833, -0.1936],\n",
       "        [ 0.0835,  0.1460, -0.1632, -0.0009, -0.1080,  0.0853,  0.1047,  0.1883,\n",
       "          0.0468,  0.2327,  0.1032, -0.0724,  0.0418,  0.1980, -0.1232, -0.1628,\n",
       "          0.1094,  0.0797, -0.0712,  0.1553]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hx # hidden state of last timestep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7f9a583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4372,  0.3701,  1.5816, -0.1556,  0.1511, -1.3495, -0.7089, -0.2434,\n",
      "         -0.0389,  1.0810],\n",
      "        [ 0.2593,  1.8514,  1.3406,  1.7659,  0.5640, -0.6749,  0.0914,  0.3948,\n",
      "          1.5457, -0.3610]])\n",
      "tensor([[ 0.9088,  0.0789, -0.0895,  0.1714, -0.1575,  1.9800,  0.7573, -0.4274,\n",
      "         -1.5918, -0.0736],\n",
      "        [-0.2723,  0.6279, -2.7544,  0.4208,  0.2516,  0.9675, -0.6870,  0.9042,\n",
      "          0.3286, -0.0742]])\n",
      "tensor([[-2.5141,  0.1140,  0.9822,  0.0681, -0.0996,  0.8033,  1.0441, -0.5201,\n",
      "          0.8059,  1.0867],\n",
      "        [ 0.1414, -1.2538, -0.3456, -0.2211, -0.7043,  0.3368,  0.0064,  0.2326,\n",
      "          0.9527, -0.4139]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):  # Iterate over the sequence length\n",
    "    print(reshaped_input[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2d55c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4372,  0.3701,  1.5816, -0.1556,  0.1511, -1.3495, -0.7089,\n",
       "          -0.2434, -0.0389,  1.0810],\n",
       "         [ 0.9088,  0.0789, -0.0895,  0.1714, -0.1575,  1.9800,  0.7573,\n",
       "          -0.4274, -1.5918, -0.0736],\n",
       "         [-2.5141,  0.1140,  0.9822,  0.0681, -0.0996,  0.8033,  1.0441,\n",
       "          -0.5201,  0.8059,  1.0867]],\n",
       "\n",
       "        [[ 0.2593,  1.8514,  1.3406,  1.7659,  0.5640, -0.6749,  0.0914,\n",
       "           0.3948,  1.5457, -0.3610],\n",
       "         [-0.2723,  0.6279, -2.7544,  0.4208,  0.2516,  0.9675, -0.6870,\n",
       "           0.9042,  0.3286, -0.0742],\n",
       "         [ 0.1414, -1.2538, -0.3456, -0.2211, -0.7043,  0.3368,  0.0064,\n",
       "           0.2326,  0.9527, -0.4139]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f83349c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4372,  0.3701,  1.5816, -0.1556,  0.1511, -1.3495, -0.7089,\n",
       "          -0.2434, -0.0389,  1.0810],\n",
       "         [ 0.2593,  1.8514,  1.3406,  1.7659,  0.5640, -0.6749,  0.0914,\n",
       "           0.3948,  1.5457, -0.3610]],\n",
       "\n",
       "        [[ 0.9088,  0.0789, -0.0895,  0.1714, -0.1575,  1.9800,  0.7573,\n",
       "          -0.4274, -1.5918, -0.0736],\n",
       "         [-0.2723,  0.6279, -2.7544,  0.4208,  0.2516,  0.9675, -0.6870,\n",
       "           0.9042,  0.3286, -0.0742]],\n",
       "\n",
       "        [[-2.5141,  0.1140,  0.9822,  0.0681, -0.0996,  0.8033,  1.0441,\n",
       "          -0.5201,  0.8059,  1.0867],\n",
       "         [ 0.1414, -1.2538, -0.3456, -0.2211, -0.7043,  0.3368,  0.0064,\n",
       "           0.2326,  0.9527, -0.4139]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3d189b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(\n",
    "            input_size=4, \n",
    "            hidden_size=10,\n",
    "            num_layers=1,\n",
    "            bidirectional= False,\n",
    "            batch_first = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e004b698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(4, 10, batch_first=True)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8b2a6dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0169, -0.1896,  0.1056,  1.3294],\n",
       "         [ 1.7862, -0.3860, -1.0516,  1.4761],\n",
       "         [ 0.7651, -0.0073,  0.7714, -1.4906]],\n",
       "\n",
       "        [[ 0.4931, -0.5488,  0.2820, -0.2617],\n",
       "         [ 1.5349,  0.2515, -0.1117,  0.5740],\n",
       "         [ 1.6791,  1.6109, -0.5240, -0.4526]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3,4)  # 2 batches, 3 tokens, each token is represented by 4 dim vector\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e38ae549",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hx,cx) = lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c60a910e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1855, -0.1394, -0.0590,  0.0404,  0.1128,  0.1281,  0.0590,\n",
       "          -0.0274, -0.0022, -0.0581],\n",
       "         [ 0.1200, -0.3064, -0.0430,  0.2128,  0.1870,  0.1861,  0.0894,\n",
       "          -0.0406,  0.0517,  0.0938],\n",
       "         [ 0.1611, -0.1037, -0.0089,  0.2342,  0.0320,  0.1737, -0.0627,\n",
       "           0.0546,  0.1800,  0.1769]],\n",
       "\n",
       "        [[ 0.1492, -0.0735,  0.0058,  0.0727,  0.0539,  0.1093, -0.0485,\n",
       "           0.0389,  0.0908,  0.0830],\n",
       "         [ 0.1247, -0.1943, -0.0582,  0.2144,  0.0857,  0.1623, -0.0242,\n",
       "           0.0601,  0.1523,  0.1715],\n",
       "         [ 0.0302, -0.1695, -0.0821,  0.3260,  0.0545,  0.0489,  0.0143,\n",
       "           0.0434,  0.2671,  0.2833]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output \n",
    "# batch size is 2\n",
    "# one element has 3 tokens \n",
    "# corresponding to each tokens we have a hidden state stored \n",
    "# in lstm most of the cases we use last hidden state of all the elements in a batch \n",
    "# since we have two batches here we will take the last hidden state of both elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "279a09c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1611, -0.1037, -0.0089,  0.2342,  0.0320,  0.1737, -0.0627,  0.0546,\n",
       "          0.1800,  0.1769],\n",
       "        [ 0.0302, -0.1695, -0.0821,  0.3260,  0.0545,  0.0489,  0.0143,  0.0434,\n",
       "          0.2671,  0.2833]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:,batch_size,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5c9bfd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 10])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hx.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "42d77c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "23fdd86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1492, -0.0735,  0.0058,  0.0727,  0.0539,  0.1093, -0.0485,  0.0389,\n",
       "          0.0908,  0.0830],\n",
       "        [ 0.1247, -0.1943, -0.0582,  0.2144,  0.0857,  0.1623, -0.0242,  0.0601,\n",
       "          0.1523,  0.1715],\n",
       "        [ 0.0302, -0.1695, -0.0821,  0.3260,  0.0545,  0.0489,  0.0143,  0.0434,\n",
       "          0.2671,  0.2833]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[output.shape[0]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9ba8db7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1611, -0.1037, -0.0089,  0.2342,  0.0320,  0.1737, -0.0627,\n",
       "           0.0546,  0.1800,  0.1769],\n",
       "         [ 0.0302, -0.1695, -0.0821,  0.3260,  0.0545,  0.0489,  0.0143,\n",
       "           0.0434,  0.2671,  0.2833]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fd3521dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3917, -0.2877, -0.0293,  0.3249,  0.0995,  0.3470, -0.1808,\n",
       "           0.0948,  0.3159,  0.3612],\n",
       "         [ 0.1171, -0.3221, -0.1907,  0.6064,  0.1275,  0.1403,  0.0414,\n",
       "           0.1372,  0.5179,  0.4662]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78f1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88b815be",
   "metadata": {},
   "source": [
    "## What if it is bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "41c522cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm = nn.LSTM(\n",
    "            input_size=4, \n",
    "            hidden_size=5,\n",
    "            num_layers=1,\n",
    "            bidirectional= True,\n",
    "            batch_first = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a280c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,3,4)  \n",
    "# 2 batches, 3 tokens, each token is represented by 4 dim vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0d092817",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hx,cx) = bi_lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3d35af13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0728,  0.0608,  0.1383,  0.1270, -0.0046, -0.2140,  0.0967,\n",
       "           0.2819,  0.0730, -0.2082],\n",
       "         [ 0.1710, -0.1659,  0.1097,  0.1377, -0.1140, -0.2165, -0.0859,\n",
       "           0.1174,  0.0380, -0.1644],\n",
       "         [ 0.3054, -0.2081,  0.0070,  0.0931, -0.1055, -0.1350, -0.1162,\n",
       "          -0.0984,  0.0561, -0.0354]],\n",
       "\n",
       "        [[-0.0525, -0.0849,  0.0346,  0.0158, -0.0629, -0.3748,  0.0809,\n",
       "           0.2623,  0.2009, -0.2269],\n",
       "         [ 0.1740, -0.2876,  0.0826,  0.1080, -0.1008, -0.1487,  0.0726,\n",
       "           0.1754,  0.1618, -0.1111],\n",
       "         [-0.0571,  0.1055,  0.1906,  0.2258,  0.0537, -0.3654,  0.3338,\n",
       "           0.3916,  0.0974,  0.1387]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output\n",
    "# output contains both directions lstm outputs\n",
    "# in forward direction, each timestep lstm hidden state has a 5 dimensional output \n",
    "# in backward direction, each timestep lstm hidden state has 5 dimensional output \n",
    "\n",
    "\n",
    "# we have batchsize 2 here \n",
    "# in the output first array has dimension (1,3,10)\n",
    "# first 5 values in the first dim corresponds to the foward direction hidden \n",
    "# second 5 values in the first dim corresponds to the backward direction (final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fb27d732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape\n",
    "# note that here the last dimension we have the value of 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "949446db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 5])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8176d2",
   "metadata": {},
   "source": [
    "## stacking multiple lstm :  output of one lstm is passed into another lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "43ee33e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0910,  0.0985,  0.1572,  0.1337,  0.0287],\n",
      "         [ 0.1093,  0.1988,  0.1030,  0.0624,  0.0398],\n",
      "         [ 0.2978,  0.2197,  0.1769,  0.0870,  0.0433],\n",
      "         [ 0.1856,  0.1130,  0.0361,  0.0512, -0.0525],\n",
      "         [-0.0332, -0.1232, -0.0547,  0.0411,  0.0160],\n",
      "         [ 0.0165,  0.0615, -0.0280,  0.0487,  0.0673],\n",
      "         [-0.0366, -0.1633, -0.1418,  0.2091, -0.0403]],\n",
      "\n",
      "        [[-0.0157, -0.0070,  0.0154,  0.1137,  0.0315],\n",
      "         [-0.0470, -0.1371, -0.0197, -0.0110,  0.0973],\n",
      "         [-0.0984, -0.1972, -0.2542,  0.0096,  0.0954],\n",
      "         [-0.0386, -0.0604, -0.1443,  0.0551,  0.0697],\n",
      "         [ 0.0350,  0.0932, -0.0109,  0.0044,  0.1797],\n",
      "         [-0.0344,  0.2124,  0.0099, -0.0873,  0.1756],\n",
      "         [ 0.0861,  0.2185,  0.0178, -0.0197,  0.1479]],\n",
      "\n",
      "        [[ 0.1495,  0.1175,  0.1209,  0.1191, -0.0998],\n",
      "         [ 0.2267,  0.1225,  0.1779,  0.2057, -0.1728],\n",
      "         [ 0.0863,  0.1031,  0.0155,  0.0363, -0.0161],\n",
      "         [ 0.1642,  0.0873,  0.0762,  0.0059,  0.0255],\n",
      "         [ 0.1415,  0.1984,  0.2511,  0.0794,  0.0315],\n",
      "         [-0.0429, -0.1292,  0.0086,  0.0694,  0.0191],\n",
      "         [-0.0544, -0.1792, -0.0241,  0.0252,  0.0380]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[0.2007, 0.0366, 0.0289, 0.0787, 0.1340],\n",
      "         [0.2973, 0.0443, 0.0480, 0.1434, 0.1573],\n",
      "         [0.3787, 0.0513, 0.0513, 0.1946, 0.1609],\n",
      "         [0.4035, 0.0440, 0.0683, 0.2001, 0.1514],\n",
      "         [0.3895, 0.0239, 0.0851, 0.1805, 0.1474],\n",
      "         [0.3849, 0.0208, 0.0874, 0.1960, 0.1581],\n",
      "         [0.3700, 0.0134, 0.0906, 0.1821, 0.1730]],\n",
      "\n",
      "        [[0.1718, 0.0287, 0.0332, 0.0648, 0.1356],\n",
      "         [0.2520, 0.0229, 0.0511, 0.0980, 0.1503],\n",
      "         [0.2649, 0.0105, 0.0646, 0.1131, 0.1635],\n",
      "         [0.2942, 0.0112, 0.0704, 0.1407, 0.1740],\n",
      "         [0.3306, 0.0200, 0.0681, 0.1803, 0.1713],\n",
      "         [0.3554, 0.0195, 0.0784, 0.2044, 0.1535],\n",
      "         [0.3878, 0.0271, 0.0780, 0.2245, 0.1584]],\n",
      "\n",
      "        [[0.2056, 0.0350, 0.0323, 0.0701, 0.1277],\n",
      "         [0.3168, 0.0452, 0.0510, 0.1298, 0.1568],\n",
      "         [0.3464, 0.0384, 0.0677, 0.1618, 0.1535],\n",
      "         [0.3890, 0.0354, 0.0722, 0.1835, 0.1484],\n",
      "         [0.4240, 0.0358, 0.0811, 0.2130, 0.1457],\n",
      "         [0.4055, 0.0192, 0.0941, 0.1906, 0.1439],\n",
      "         [0.3900, 0.0040, 0.0980, 0.1738, 0.1439]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define custom model class\n",
    "class StackedLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(StackedLSTM, self).__init__()\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        for _ in range(num_layers):\n",
    "            self.lstm_layers.append(nn.LSTM(input_size, hidden_size, batch_first=True))\n",
    "            input_size = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_layers):\n",
    "            x, _ = self.lstm_layers[i](x)\n",
    "            print(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_size = 4\n",
    "hidden_size = 5\n",
    "num_layers = 2\n",
    "\n",
    "# Create an instance of the model\n",
    "model = StackedLSTM(input_size, hidden_size, num_layers)\n",
    "\n",
    "# Generate some input data\n",
    "batch_size = 3\n",
    "sequence_length = 7\n",
    "input_data = torch.randn(batch_size, sequence_length, input_size)\n",
    "# print(input_data)\n",
    "\n",
    "# Pass the input through the model\n",
    "output = model(input_data)\n",
    "\n",
    "# Print the output shape\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7b218e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2007, 0.0366, 0.0289, 0.0787, 0.1340],\n",
       "         [0.2973, 0.0443, 0.0480, 0.1434, 0.1573],\n",
       "         [0.3787, 0.0513, 0.0513, 0.1946, 0.1609],\n",
       "         [0.4035, 0.0440, 0.0683, 0.2001, 0.1514],\n",
       "         [0.3895, 0.0239, 0.0851, 0.1805, 0.1474],\n",
       "         [0.3849, 0.0208, 0.0874, 0.1960, 0.1581],\n",
       "         [0.3700, 0.0134, 0.0906, 0.1821, 0.1730]],\n",
       "\n",
       "        [[0.1718, 0.0287, 0.0332, 0.0648, 0.1356],\n",
       "         [0.2520, 0.0229, 0.0511, 0.0980, 0.1503],\n",
       "         [0.2649, 0.0105, 0.0646, 0.1131, 0.1635],\n",
       "         [0.2942, 0.0112, 0.0704, 0.1407, 0.1740],\n",
       "         [0.3306, 0.0200, 0.0681, 0.1803, 0.1713],\n",
       "         [0.3554, 0.0195, 0.0784, 0.2044, 0.1535],\n",
       "         [0.3878, 0.0271, 0.0780, 0.2245, 0.1584]],\n",
       "\n",
       "        [[0.2056, 0.0350, 0.0323, 0.0701, 0.1277],\n",
       "         [0.3168, 0.0452, 0.0510, 0.1298, 0.1568],\n",
       "         [0.3464, 0.0384, 0.0677, 0.1618, 0.1535],\n",
       "         [0.3890, 0.0354, 0.0722, 0.1835, 0.1484],\n",
       "         [0.4240, 0.0358, 0.0811, 0.2130, 0.1457],\n",
       "         [0.4055, 0.0192, 0.0941, 0.1906, 0.1439],\n",
       "         [0.3900, 0.0040, 0.0980, 0.1738, 0.1439]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output \n",
    "# for 3 elements in the batch \n",
    "# we have 4 vectors corresponding to each tokens \n",
    "# each such vector is represented in 5 dimensional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e3006129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 8])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "52da953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_size = 3\n",
    "hidden_size = 4\n",
    "num_layers = 4\n",
    "\n",
    "# Create a stacked LSTM model\n",
    "model = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,bidirectional=True)\n",
    "\n",
    "# Generate some input data\n",
    "batch_size = 2\n",
    "sequence_length = 7\n",
    "input_data = torch.randn(batch_size, sequence_length, input_size)\n",
    "\n",
    "# Pass the input through the model\n",
    "output, (hidden,cell) = model(input_data)\n",
    "\n",
    "# Print the output shape\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "abdcf599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0810,  0.0551,  0.0185,  0.0093,  0.0895,  0.2262, -0.2059,\n",
       "           0.1461],\n",
       "         [ 0.1209,  0.0776,  0.0230, -0.0005,  0.0773,  0.2246, -0.2079,\n",
       "           0.1392],\n",
       "         [ 0.1406,  0.0873,  0.0222, -0.0168,  0.0677,  0.2208, -0.2060,\n",
       "           0.1294],\n",
       "         [ 0.1501,  0.0901,  0.0174, -0.0378,  0.0600,  0.2118, -0.2012,\n",
       "           0.1197],\n",
       "         [ 0.1519,  0.0899,  0.0121, -0.0579,  0.0521,  0.1936, -0.1910,\n",
       "           0.1078],\n",
       "         [ 0.1511,  0.0864,  0.0046, -0.0797,  0.0437,  0.1626, -0.1692,\n",
       "           0.0932],\n",
       "         [ 0.1509,  0.0809, -0.0058, -0.1077,  0.0306,  0.1054, -0.1215,\n",
       "           0.0665]],\n",
       "\n",
       "        [[ 0.0808,  0.0559,  0.0189,  0.0096,  0.0954,  0.2307, -0.2055,\n",
       "           0.1486],\n",
       "         [ 0.1231,  0.0798,  0.0229, -0.0032,  0.0858,  0.2319, -0.2070,\n",
       "           0.1453],\n",
       "         [ 0.1446,  0.0883,  0.0194, -0.0246,  0.0754,  0.2270, -0.2053,\n",
       "           0.1362],\n",
       "         [ 0.1554,  0.0892,  0.0114, -0.0519,  0.0671,  0.2175, -0.2006,\n",
       "           0.1262],\n",
       "         [ 0.1587,  0.0883,  0.0034, -0.0795,  0.0584,  0.1984, -0.1909,\n",
       "           0.1140],\n",
       "         [ 0.1570,  0.0852, -0.0047, -0.1048,  0.0464,  0.1638, -0.1698,\n",
       "           0.0960],\n",
       "         [ 0.1539,  0.0787, -0.0147, -0.1312,  0.0300,  0.1040, -0.1222,\n",
       "           0.0661]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "523b895a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 4])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape  # 4 layers * bidirection, 2 batch, hidden_size is 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0430bd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 8])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5156cd34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902966bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
