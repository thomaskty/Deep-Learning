{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d8d059-8eef-4884-95eb-1f976bd41953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version = 3.4.1\n",
      "Tensorflow version = 2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "print(f'keras version = {keras.__version__}')\n",
    "print(f'Tensorflow version = {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ffe613-963d-4b2c-9611-f61c8b3f616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63e673d-beec-4cc3-84ea-b88ac6fc0d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a54e0d3-775e-439a-9855-30c06ab5fa1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.src.models.sequential.Sequential"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b4b22f-5aab-4677-84c5-6b21eeab572f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "979ed662-c488-4a10-8c9d-ba10f55b72e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.src.layers.core.dense.Dense"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "989378d2-b8ca-4bd5-aa2f-e0cb500d5a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/BankChurners.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd30804c-d218-4370-b151-125498ce4d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [i.lower().replace(' ','_') for i in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44b117a1-8278-4083-85e5-6037e2a9631a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attrition_flag</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>dependent_count</th>\n",
       "      <th>education_level</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>income_category</th>\n",
       "      <th>card_category</th>\n",
       "      <th>months_on_book</th>\n",
       "      <th>total_relationship_count</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_open_to_buy</th>\n",
       "      <th>total_amt_chng_q4_q1</th>\n",
       "      <th>total_trans_amt</th>\n",
       "      <th>total_trans_ct</th>\n",
       "      <th>total_ct_chng_q4_q1</th>\n",
       "      <th>avg_utilization_ratio</th>\n",
       "      <th>unnamed:_20</th>\n",
       "      <th>unnamed:_21</th>\n",
       "      <th>unnamed:_22</th>\n",
       "      <th>unnamed:_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>High School</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>796.0</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      attrition_flag  customer_age gender  dependent_count education_level  \\\n",
       "0  Existing Customer            45      M                3     High School   \n",
       "1  Existing Customer            49      F                5        Graduate   \n",
       "2  Existing Customer            51      M                3        Graduate   \n",
       "3  Existing Customer            40      F                4     High School   \n",
       "4  Existing Customer            40      M                3      Uneducated   \n",
       "\n",
       "  marital_status income_category card_category  months_on_book  \\\n",
       "0        Married     $60K - $80K          Blue              39   \n",
       "1         Single  Less than $40K          Blue              44   \n",
       "2        Married    $80K - $120K          Blue              36   \n",
       "3        Unknown  Less than $40K          Blue              34   \n",
       "4        Married     $60K - $80K          Blue              21   \n",
       "\n",
       "   total_relationship_count  ...  avg_open_to_buy  total_amt_chng_q4_q1  \\\n",
       "0                         5  ...          11914.0                 1.335   \n",
       "1                         6  ...           7392.0                 1.541   \n",
       "2                         4  ...           3418.0                 2.594   \n",
       "3                         3  ...            796.0                 1.405   \n",
       "4                         5  ...           4716.0                 2.175   \n",
       "\n",
       "   total_trans_amt  total_trans_ct  total_ct_chng_q4_q1  \\\n",
       "0             1144              42                1.625   \n",
       "1             1291              33                3.714   \n",
       "2             1887              20                2.333   \n",
       "3             1171              20                2.333   \n",
       "4              816              28                2.500   \n",
       "\n",
       "   avg_utilization_ratio  unnamed:_20  unnamed:_21  unnamed:_22  unnamed:_23  \n",
       "0                  0.061          NaN          NaN          NaN          NaN  \n",
       "1                  0.105          NaN          NaN          NaN          NaN  \n",
       "2                  0.000          NaN          NaN          NaN          NaN  \n",
       "3                  0.760          NaN          NaN          NaN          NaN  \n",
       "4                  0.000          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ade4f8e-2e1f-4342-80f8-d6cb40ced968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Existing Customer': None, 'Attrited Customer': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict.fromkeys(df.attrition_flag.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c33af2b8-115f-40c7-a207-aeb84959190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mappings = {'Existing Customer': 0, 'Attrited Customer': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66fd93fe-a7ea-4fec-b2c1-5c0edf343037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['attrition_flag'].map(target_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f0b518f-c8e7-4ec5-89cc-35e88708302a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attrition_flag', 'gender', 'education_level', 'marital_status', 'income_category', 'card_category', 'unnamed:_20', 'unnamed:_21', 'unnamed:_22', 'unnamed:_23']\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['attrition_flag','gender','education_level','marital_status','income_category','card_category']\n",
    "drop_columns_part1 = [i for i in df.columns if 'unnamed' in i]\n",
    "drop_cols_final= drop_columns + drop_columns_part1 \n",
    "print(drop_cols_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f1d5293-6234-4eb4-b34a-1cf144d2a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(drop_cols_final,axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b74640e4-82e0-4b4f-bdea-b62a89983350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10127, 15)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a8b1631-cce8-43f8-b6ef-e154ada3c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd8402f6-d3f7-4127-b536-34d3db835ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data,method='standard',feature_range=(0,1)):\n",
    "   if len(data.shape) ==1:\n",
    "       data = data.reshape(-1,1)\n",
    "   if method.lower()=='standard':\n",
    "       scaler = preprocessing.StandardScaler()\n",
    "   elif method.lower()=='minmax':\n",
    "       scaler = preprocessing.MinMaxScaler(feature_range=feature_range)\n",
    "   else:\n",
    "       raise ValueError('Method must be either \"standard\" or \"minmax\"')\n",
    "   scaled_data = scaler.fit_transform(data)\n",
    "   return scaled_data,scaler\n",
    "\n",
    "def inverse_scale_data(scaled_data,scaler):\n",
    "   if len(scaled_data.shape)==1:\n",
    "       scaled_data = scaled_data.reshape(-1,1)\n",
    "   original_data = scaler.inverse_transform(scaled_data)\n",
    "   return original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed5379f4-d3b8-4816-9b2e-3a1663bffa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('target',axis=1)\n",
    "y = df['target']\n",
    "features = x.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "961396f4-3b01-41f7-ac7f-f38be8a45ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled,scaler = scale_data(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1524293-100d-4572-9c9a-6359d9939120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(inverse_scale_data(x_scaled,scaler),columns = features).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3083a8ee-76ee-49d4-919b-9252d45ecc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10127, 14), (10127,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ba9b2d2-e2bb-4c40-8076-9eae98dbd4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   21,    39,    51, ..., 10124, 10125, 10126])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_of_ones = np.where(y == 1)[0]\n",
    "indexes_of_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "582f354b-8e31-45c3-9662-1aadcf3a7dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1627"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexes_of_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6c7cec4-0299-44fb-b1e0-f69771677cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    8500\n",
       "1    1627\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f76d2eb1-fd25-4a63-95fe-ceba82cc12ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1627, 14)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_with_ones = x_scaled[indexes_of_ones]\n",
    "records_with_ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd4d5533-60ef-45d9-9755-fdc3b4d4e98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/Documents/GitHub/Deep-Learning/.conda/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(101)\n",
    "# Define the generator network\n",
    "def build_generator(latent_dim, output_dim):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(64, input_shape=(latent_dim,)))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(8,activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(output_dim, activation='sigmoid'))\n",
    "    return model\n",
    "# Dimensionality of the input noise for the generator\n",
    "latent_dim = 128\n",
    "len_features = len(features)\n",
    "generator = build_generator(latent_dim, len_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "294d1f3e-cc73-431a-97e5-d378208bde78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/Documents/GitHub/Deep-Learning/.conda/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,425</span> (21.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,425\u001b[0m (21.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,425</span> (21.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,425\u001b[0m (21.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(101)\n",
    "# Define the discriminator network\n",
    "def build_discriminator(input_dim):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape = (input_dim,)))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(8, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator(len_features)\n",
    "print(discriminator.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "798f964f-c863-4dab-b868-f3e6a8b096a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,838</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,425</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │        \u001b[38;5;34m12,838\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m5,425\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,263</span> (71.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,263\u001b[0m (71.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,838</span> (50.15 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,838\u001b[0m (50.15 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,425</span> (21.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,425\u001b[0m (21.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes precision using TensorFlow.\n",
    "\n",
    "    Args:\n",
    "        y_true: Ground truth (binary labels, tensor).\n",
    "        y_pred: Predicted values (probabilities or binary predictions, tensor).\n",
    "\n",
    "    Returns:\n",
    "        Precision value (tensor scalar).\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "    \n",
    "    epsilon = tf.keras.backend.epsilon()  # Small constant for numerical stability\n",
    "    y_pred_rounded = tf.round(tf.clip_by_value(y_pred, 0, 1))\n",
    "    \n",
    "    true_positives = tf.reduce_sum(tf.round(y_true * y_pred_rounded))\n",
    "    predicted_positives = tf.reduce_sum(y_pred_rounded)\n",
    "    \n",
    "    precision_value = true_positives / (predicted_positives + epsilon)\n",
    "    return precision_value\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes recall using TensorFlow.\n",
    "\n",
    "    Args:\n",
    "        y_true: Ground truth (binary labels, tensor).\n",
    "        y_pred: Predicted values (probabilities or binary predictions, tensor).\n",
    "\n",
    "    Returns:\n",
    "        Recall value (tensor scalar).\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "    \n",
    "    epsilon = tf.keras.backend.epsilon()  # Small constant for numerical stability\n",
    "    y_pred_rounded = tf.round(tf.clip_by_value(y_pred, 0, 1))\n",
    "    \n",
    "    true_positives = tf.reduce_sum(tf.round(y_true * y_pred_rounded))\n",
    "    possible_positives = tf.reduce_sum(tf.round(y_true))\n",
    "    \n",
    "    recall_value = true_positives / (possible_positives + epsilon)\n",
    "    return recall_value\n",
    "\n",
    "\n",
    "discriminator.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001,beta_1=0.5),\n",
    "    loss='binary_crossentropy',  \n",
    "    metrics=[precision,recall]\n",
    ")\n",
    "\n",
    "def generator_loss_log_d(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Generator loss for GANs implemented using TensorFlow operations.\n",
    "    Encourages y_pred values to approach 1.\n",
    "\n",
    "    Args:\n",
    "        y_true: Ground truth labels (tensor).\n",
    "        y_pred: Predicted probabilities (tensor).\n",
    "\n",
    "    Returns:\n",
    "        Scalar loss value (tensor).\n",
    "    \"\"\"\n",
    "    epsilon = tf.keras.backend.epsilon()  # Small constant to prevent log(0)\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1.0)  # Ensure y_pred is within [epsilon, 1]\n",
    "    return -tf.reduce_mean(tf.math.log(y_pred))\n",
    "\n",
    "\n",
    "# Build and compile the GANs upper optimization loop combining generator and discriminator\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = keras.Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5),\n",
    "        loss=generator_loss_log_d\n",
    "    )\n",
    "    return model\n",
    "\n",
    "gan = build_gan(generator, discriminator)\n",
    "print(gan.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a62eb0b8-5866-4981-a075-b2e2b7621db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "import os \n",
    "import logging\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# Redirect TensorFlow logs to a file\n",
    "log_file = open(\"tensorflow_logs.txt\", \"w\")\n",
    "tf.get_logger().addHandler(logging.StreamHandler(log_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d219380-c65c-415e-b265-5722a06fce5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch: 0 - D Loss: [0.7496842  0.50131965 0.29815328] - G Loss: [0.7496673464775085, 0.7496673464775085, 0.5008787512779236, 0.2978910505771637]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 1 - D Loss: [0.749365   0.501315   0.29798445] - G Loss: [0.7492984533309937, 0.7492984533309937, 0.5008756518363953, 0.29772329330444336]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 2 - D Loss: [0.7494275  0.50131047 0.2978168 ] - G Loss: [0.7494401931762695, 0.7494401931762695, 0.5008726119995117, 0.29755672812461853]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 3 - D Loss: [0.74951327 0.5013059  0.2972152 ] - G Loss: [0.7495114803314209, 0.7495114803314209, 0.5008695721626282, 0.29695650935173035]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 4 - D Loss: [0.7500193 0.5013013 0.2968346] - G Loss: [0.7499794960021973, 0.7499794960021973, 0.5008665323257446, 0.296577125787735]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 5 - D Loss: [0.74972284 0.5012968  0.2968887 ] - G Loss: [0.7497015595436096, 0.7497015595436096, 0.5008635520935059, 0.2966321110725403]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 6 - D Loss: [0.75045717 0.50129235 0.29651183] - G Loss: [0.7504969239234924, 0.7504969239234924, 0.5008605718612671, 0.2962564527988434]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 7 - D Loss: [0.75027424 0.50128794 0.29656672] - G Loss: [0.7502076029777527, 0.7502076029777527, 0.5008576512336731, 0.2963121831417084]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 8 - D Loss: [0.7498726  0.5012835  0.29683512] - G Loss: [0.7498578429222107, 0.7498578429222107, 0.5008547306060791, 0.2965812087059021]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 9 - D Loss: [0.74965405 0.5012791  0.29688853] - G Loss: [0.7496071457862854, 0.7496071457862854, 0.5008518099784851, 0.2966354489326477]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 10 - D Loss: [0.7494457 0.5012748 0.297154 ] - G Loss: [0.749519407749176, 0.749519407749176, 0.5008488893508911, 0.29690152406692505]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 11 - D Loss: [0.7503314 0.5012705 0.2967826] - G Loss: [0.7502443194389343, 0.7502443194389343, 0.5008460283279419, 0.2965312898159027]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 12 - D Loss: [0.7501031 0.5012662 0.2966247] - G Loss: [0.7500630021095276, 0.7500630021095276, 0.5008431673049927, 0.2963743805885315]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 13 - D Loss: [0.749555   0.50126195 0.29667807] - G Loss: [0.7495747208595276, 0.7495747208595276, 0.5008403658866882, 0.2964285612106323]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 14 - D Loss: [0.74935853 0.50125766 0.29652157] - G Loss: [0.7492930293083191, 0.7492930293083191, 0.500837504863739, 0.29627302289009094]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 15 - D Loss: [0.74942803 0.5012535  0.29615727] - G Loss: [0.7494352459907532, 0.7494352459907532, 0.5008347034454346, 0.2959098517894745]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 16 - D Loss: [0.7492986  0.5012493  0.29600352] - G Loss: [0.7492691874504089, 0.7492691874504089, 0.5008319616317749, 0.29575708508491516]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 17 - D Loss: [0.74898887 0.50124514 0.29647323] - G Loss: [0.7490772604942322, 0.7490772604942322, 0.5008291602134705, 0.29622718691825867]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 18 - D Loss: [0.74864763 0.501241   0.29693982] - G Loss: [0.7485957145690918, 0.7485957145690918, 0.5008264183998108, 0.29669421911239624]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch: 19 - D Loss: [0.74896204 0.5012369  0.29657894] - G Loss: [0.748960018157959, 0.748960018157959, 0.5008237361907959, 0.296334445476532]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 20 - D Loss: [0.7486304  0.50123286 0.29642582] - G Loss: [0.7485628724098206, 0.7485628724098206, 0.5008209943771362, 0.2961822748184204]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 21 - D Loss: [0.7483064  0.5012288  0.29668325] - G Loss: [0.7482898831367493, 0.7482898831367493, 0.5008183121681213, 0.2964402735233307]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 22 - D Loss: [0.7478094  0.5012249  0.29734713] - G Loss: [0.7477649450302124, 0.7477649450302124, 0.5008156895637512, 0.2971044182777405]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 23 - D Loss: [0.7478729  0.5012208  0.29739648] - G Loss: [0.7478467226028442, 0.7478467226028442, 0.5008130073547363, 0.2971544861793518]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 24 - D Loss: [0.747527   0.5012169  0.29785097] - G Loss: [0.7475334405899048, 0.7475334405899048, 0.5008103847503662, 0.2976093888282776]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 25 - D Loss: [0.74728936 0.50121295 0.29789835] - G Loss: [0.7472155690193176, 0.7472155690193176, 0.5008077621459961, 0.2976575195789337]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 26 - D Loss: [0.7468822  0.501209   0.29814684] - G Loss: [0.7468545436859131, 0.7468545436859131, 0.500805139541626, 0.2979066073894501]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 27 - D Loss: [0.746528   0.50120515 0.2985946 ] - G Loss: [0.7465264797210693, 0.7465264797210693, 0.5008025765419006, 0.29835474491119385]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 28 - D Loss: [0.7463131  0.5012013  0.29883927] - G Loss: [0.7462580800056458, 0.7462580800056458, 0.5008000135421753, 0.2985999882221222]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 29 - D Loss: [0.74620694 0.50119746 0.29888287] - G Loss: [0.7461379170417786, 0.7461379170417786, 0.50079745054245, 0.2986443340778351]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 30 - D Loss: [0.7456215  0.50119364 0.29932398] - G Loss: [0.7455070614814758, 0.7455070614814758, 0.5007948875427246, 0.2990858554840088]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 31 - D Loss: [0.74502224 0.5011898  0.2997623 ] - G Loss: [0.7450524568557739, 0.7450524568557739, 0.500792384147644, 0.29952457547187805]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 32 - D Loss: [0.745288  0.5011861 0.3000002] - G Loss: [0.7453016638755798, 0.7453016638755798, 0.5007898807525635, 0.299763023853302]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 33 - D Loss: [0.74598014 0.5011823  0.29944858] - G Loss: [0.7459515333175659, 0.7459515333175659, 0.5007873773574829, 0.29921260476112366]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 34 - D Loss: [0.74540484 0.5011786  0.30007875] - G Loss: [0.7454007267951965, 0.7454007267951965, 0.5007849335670471, 0.2998430132865906]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 35 - D Loss: [0.74491465 0.5011749  0.30050918] - G Loss: [0.7448053359985352, 0.7448053359985352, 0.5007824897766113, 0.3002738654613495]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 36 - D Loss: [0.7443446  0.50117123 0.30093694] - G Loss: [0.7442737221717834, 0.7442737221717834, 0.5007800459861755, 0.3007020354270935]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 37 - D Loss: [0.74448955 0.50116765 0.3003893 ] - G Loss: [0.7445398569107056, 0.7445398569107056, 0.5007776021957397, 0.30015552043914795]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 38 - D Loss: [0.7445029  0.501164   0.30023295] - G Loss: [0.7445650100708008, 0.7445650100708008, 0.5007752180099487, 0.30000001192092896]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 39 - D Loss: [0.74456066 0.5011604  0.30027086] - G Loss: [0.7445729374885559, 0.7445729374885559, 0.5007727742195129, 0.3000386357307434]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 40 - D Loss: [0.7444321  0.5011568  0.29992306] - G Loss: [0.7443832755088806, 0.7443832755088806, 0.5007703900337219, 0.2996918261051178]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 41 - D Loss: [0.74425936 0.50115323 0.29996175] - G Loss: [0.7442105412483215, 0.7442105412483215, 0.5007680654525757, 0.29973119497299194]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 42 - D Loss: [0.7439393  0.5011497  0.30019176] - G Loss: [0.7440536618232727, 0.7440536618232727, 0.5007656812667847, 0.29996171593666077]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 43 - D Loss: [0.7440108  0.5011462  0.30003837] - G Loss: [0.7439568638801575, 0.7439568638801575, 0.5007633566856384, 0.29980915784835815]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch: 44 - D Loss: [0.7436903  0.50114274 0.30026674] - G Loss: [0.7437089681625366, 0.7437089681625366, 0.5007610321044922, 0.30003803968429565]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 45 - D Loss: [0.74360776 0.5011392  0.30049372] - G Loss: [0.7436078190803528, 0.7436078190803528, 0.500758707523346, 0.3002655506134033]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 46 - D Loss: [0.7433375  0.5011358  0.30053008] - G Loss: [0.7432626485824585, 0.7432626485824585, 0.5007564425468445, 0.30030256509780884]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 47 - D Loss: [0.74300706 0.50113237 0.30018884] - G Loss: [0.7429519295692444, 0.7429519295692444, 0.500754177570343, 0.29996228218078613]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch: 48 - D Loss: [0.7435955  0.5011289  0.29947346] - G Loss: [0.7435429096221924, 0.7435429096221924, 0.5007518529891968, 0.2992481291294098]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 49 - D Loss: [0.7432865  0.5011256  0.29951257] - G Loss: [0.7432922124862671, 0.7432922124862671, 0.5007496476173401, 0.2992878556251526]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 50 - D Loss: [0.74322724 0.50112224 0.2995514 ] - G Loss: [0.7432183027267456, 0.7432183027267456, 0.5007473826408386, 0.2993273437023163]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 51 - D Loss: [0.7428914  0.5011189  0.29977646] - G Loss: [0.7428279519081116, 0.7428279519081116, 0.5007451772689819, 0.29955291748046875]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 52 - D Loss: [0.74251246 0.5011155  0.30018604] - G Loss: [0.7424843311309814, 0.7424843311309814, 0.5007429122924805, 0.2999628484249115]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 53 - D Loss: [0.7422213 0.5011122 0.3004079] - G Loss: [0.7422302961349487, 0.7422302961349487, 0.5007407665252686, 0.3001851737499237]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 54 - D Loss: [0.74213904 0.5011089  0.30062842] - G Loss: [0.7421234846115112, 0.7421234846115112, 0.5007385611534119, 0.30040621757507324]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 55 - D Loss: [0.74164087 0.50110567 0.30103183] - G Loss: [0.7416127324104309, 0.7416127324104309, 0.5007363557815552, 0.3008100092411041]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 56 - D Loss: [0.7412548 0.5011024 0.3014329] - G Loss: [0.7412236928939819, 0.7412236928939819, 0.5007342100143433, 0.3012114465236664]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 57 - D Loss: [0.7408353  0.50109917 0.3016485 ] - G Loss: [0.7407663464546204, 0.7407663464546204, 0.5007320642471313, 0.3014275133609772]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 58 - D Loss: [0.74050283 0.50109595 0.3014976 ] - G Loss: [0.7404899001121521, 0.7404899001121521, 0.5007299184799194, 0.30127736926078796]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 59 - D Loss: [0.74033093 0.5010928  0.30152965] - G Loss: [0.7402742505073547, 0.7402742505073547, 0.5007277727127075, 0.3013100326061249]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 60 - D Loss: [0.74025846 0.5010896  0.30137998] - G Loss: [0.7402545213699341, 0.7402545213699341, 0.5007256865501404, 0.30116111040115356]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 61 - D Loss: [0.7408612  0.5010865  0.30105013] - G Loss: [0.7409561276435852, 0.7409561276435852, 0.5007236003875732, 0.3008321225643158]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 62 - D Loss: [0.7406815 0.5010833 0.3014442] - G Loss: [0.7407399415969849, 0.7407399415969849, 0.5007215142250061, 0.30122655630111694]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 63 - D Loss: [0.7406559  0.50108016 0.30147603] - G Loss: [0.7406467795372009, 0.7406467795372009, 0.500719428062439, 0.30125898122787476]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 64 - D Loss: [0.74017143 0.50107706 0.30186665] - G Loss: [0.7401653528213501, 0.7401653528213501, 0.5007173418998718, 0.30164992809295654]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 65 - D Loss: [0.73981667 0.50107396 0.30171812] - G Loss: [0.7397889494895935, 0.7397889494895935, 0.5007153153419495, 0.30150213837623596]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 66 - D Loss: [0.7397836 0.5010709 0.3017489] - G Loss: [0.7397372722625732, 0.7397372722625732, 0.5007132887840271, 0.3015335202217102]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 67 - D Loss: [0.7396383  0.5010679  0.30195743] - G Loss: [0.739595353603363, 0.739595353603363, 0.5007112622261047, 0.3017425239086151]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 68 - D Loss: [0.73988724 0.50106484 0.30180997] - G Loss: [0.7398631572723389, 0.7398631572723389, 0.5007092356681824, 0.3015957474708557]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 69 - D Loss: [0.73969245 0.5010618  0.30184022] - G Loss: [0.7396737337112427, 0.7396737337112427, 0.50070720911026, 0.301626592874527]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 70 - D Loss: [0.7397714  0.5010588  0.30169386] - G Loss: [0.7397797703742981, 0.7397797703742981, 0.5007052421569824, 0.3014809489250183]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 71 - D Loss: [0.73951054 0.50105584 0.30207616] - G Loss: [0.7395121455192566, 0.7395121455192566, 0.5007032155990601, 0.30186358094215393]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 72 - D Loss: [0.7395878  0.50105286 0.30192995] - G Loss: [0.739592432975769, 0.739592432975769, 0.5007012486457825, 0.3017180860042572]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 73 - D Loss: [0.7394777  0.50104994 0.30195957] - G Loss: [0.7395079135894775, 0.7395079135894775, 0.5006992816925049, 0.30174824595451355]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 74 - D Loss: [0.73946035 0.501047   0.30181453] - G Loss: [0.7395709753036499, 0.7395709753036499, 0.5006973743438721, 0.30160391330718994]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 75 - D Loss: [0.7393818  0.5010441  0.30201823] - G Loss: [0.7393540740013123, 0.7393540740013123, 0.5006954073905945, 0.30180805921554565]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 76 - D Loss: [0.7393526  0.5010412  0.30170035] - G Loss: [0.7393307685852051, 0.7393307685852051, 0.5006935000419617, 0.30149099230766296]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 77 - D Loss: [0.739056   0.5010383  0.30173028] - G Loss: [0.739052951335907, 0.739052951335907, 0.5006915926933289, 0.3015214502811432]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 78 - D Loss: [0.7387806  0.50103545 0.30210504] - G Loss: [0.73876953125, 0.73876953125, 0.5006896257400513, 0.3018965423107147]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 79 - D Loss: [0.73936313 0.5010326  0.3019616 ] - G Loss: [0.7394065856933594, 0.7394065856933594, 0.5006877779960632, 0.30175378918647766]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 80 - D Loss: [0.73907506 0.50102973 0.3021621 ] - G Loss: [0.7390668392181396, 0.7390668392181396, 0.5006858706474304, 0.3019547462463379]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 81 - D Loss: [0.7393155  0.5010269  0.30236155] - G Loss: [0.7392932772636414, 0.7392932772636414, 0.5006840229034424, 0.3021545708179474]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch: 82 - D Loss: [0.7392279  0.5010241  0.30255985] - G Loss: [0.7392796277999878, 0.7392796277999878, 0.5006821155548096, 0.3023533523082733]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 83 - D Loss: [0.73912    0.5010213  0.30241674] - G Loss: [0.7391269207000732, 0.7391269207000732, 0.5006802678108215, 0.30221089720726013]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 84 - D Loss: [0.7390114 0.5010185 0.3022744] - G Loss: [0.7389972805976868, 0.7389972805976868, 0.5006784200668335, 0.30206918716430664]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 85 - D Loss: [0.7388685  0.5010158  0.30247134] - G Loss: [0.7389179468154907, 0.7389179468154907, 0.5006765723228455, 0.30226656794548035]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 86 - D Loss: [0.73880076 0.50101304 0.30232966] - G Loss: [0.7388145327568054, 0.7388145327568054, 0.5006747841835022, 0.3021255135536194]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 87 - D Loss: [0.7390969  0.5010103  0.30235705] - G Loss: [0.7390841245651245, 0.7390841245651245, 0.5006729364395142, 0.30215343832969666]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 88 - D Loss: [0.73883027 0.5010076  0.3025522 ] - G Loss: [0.7388058304786682, 0.7388058304786682, 0.5006711483001709, 0.3023490011692047]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 89 - D Loss: [0.73835343 0.50100493 0.30308115] - G Loss: [0.7382492423057556, 0.7382492423057556, 0.5006693601608276, 0.30287817120552063]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 90 - D Loss: [0.7383152  0.5010022  0.30310634] - G Loss: [0.7382917404174805, 0.7382917404174805, 0.5006675720214844, 0.3029038608074188]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 91 - D Loss: [0.73815036 0.50099957 0.30329794] - G Loss: [0.738183319568634, 0.738183319568634, 0.5006657838821411, 0.30309587717056274]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 92 - D Loss: [0.73792505 0.5009969  0.3031563 ] - G Loss: [0.7379248738288879, 0.7379248738288879, 0.5006639957427979, 0.30295485258102417]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 93 - D Loss: [0.7375237  0.50099427 0.30318105] - G Loss: [0.7374696731567383, 0.7374696731567383, 0.5006622672080994, 0.30298012495040894]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 94 - D Loss: [0.73730165 0.5009916  0.30337092] - G Loss: [0.7372438907623291, 0.7372438907623291, 0.5006604790687561, 0.30317041277885437]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 95 - D Loss: [0.7370832  0.500989   0.30355978] - G Loss: [0.7370266318321228, 0.7370266318321228, 0.5006587505340576, 0.3033596873283386]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 96 - D Loss: [0.7370317  0.5009864  0.30341893] - G Loss: [0.736987292766571, 0.736987292766571, 0.5006570219993591, 0.30321943759918213]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch: 97 - D Loss: [0.7370181  0.50098383 0.3031149 ] - G Loss: [0.7369766235351562, 0.7369766235351562, 0.5006552934646606, 0.30291610956192017]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Epoch: 98 - D Loss: [0.73704886 0.5009813  0.30281243] - G Loss: [0.7370392680168152, 0.7370392680168152, 0.5006536245346069, 0.30261439085006714]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch: 99 - D Loss: [0.7368587  0.5009787  0.30300078] - G Loss: [0.7368535399436951, 0.7368535399436951, 0.5006518959999084, 0.3028031289577484]\n"
     ]
    }
   ],
   "source": [
    "# Training loop for the GANs\n",
    "for epoch in range(epochs):\n",
    "    discriminator.trainable = True\n",
    "    generator.trainable = False\n",
    "\n",
    "    # Random sampling from the real target data ( where target = 1) \n",
    "    real_ones_samples = records_with_ones[np.random.randint(0, len(indexes_of_ones), batch_size)]\n",
    "\n",
    "    # Generate fake fraud samples using the generator\n",
    "    noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "    fake_ones_samples = generator.predict(noise)\n",
    "\n",
    "    # Create labels for real and fake fraud samples\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "    # Train the discriminator on real and fake fraud samples\n",
    "    d_loss_real = discriminator.train_on_batch(real_ones_samples, real_labels)\n",
    "    d_loss_fake = discriminator.train_on_batch(fake_ones_samples, fake_labels)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Train generator (freeze discriminator)\n",
    "    discriminator.trainable = False\n",
    "    generator.trainable = True\n",
    "\n",
    "    # Generate synthetic fraud samples and create labels for training the generator\n",
    "    noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "    valid_labels = np.ones((batch_size, 1))\n",
    "\n",
    "    # Train the generator to generate samples that \"fool\" the discriminator\n",
    "    g_loss = gan.train_on_batch(noise, valid_labels)\n",
    "    g_loss = [i.item() for i in g_loss]\n",
    "    # Print the progress\n",
    "    if epoch % 1 == 0:\n",
    "        print(\"Epoch: {} - D Loss: {} - G Loss: {}\".format(epoch,d_loss,g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f65cdf98-3f57-408f-b036-b068f1998ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(0,1,size = (100,int(latent_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cd25b67d-9e69-488d-be88-d3cdf31a06d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step\n"
     ]
    }
   ],
   "source": [
    "synthetic_data = generator.predict(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec2c84a4-0e0b-44b6-9827-05441d01f06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 14)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fe8fdf41-50e9-45fd-a779-b9b7f06e0ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_age</th>\n",
       "      <th>dependent_count</th>\n",
       "      <th>months_on_book</th>\n",
       "      <th>total_relationship_count</th>\n",
       "      <th>months_inactive_12_mon</th>\n",
       "      <th>contacts_count_12_mon</th>\n",
       "      <th>credit_limit</th>\n",
       "      <th>total_revolving_bal</th>\n",
       "      <th>avg_open_to_buy</th>\n",
       "      <th>total_amt_chng_q4_q1</th>\n",
       "      <th>total_trans_amt</th>\n",
       "      <th>total_trans_ct</th>\n",
       "      <th>total_ct_chng_q4_q1</th>\n",
       "      <th>avg_utilization_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.630863</td>\n",
       "      <td>3.080832</td>\n",
       "      <td>41.161160</td>\n",
       "      <td>4.759431</td>\n",
       "      <td>2.916995</td>\n",
       "      <td>2.985534</td>\n",
       "      <td>11411.318359</td>\n",
       "      <td>1534.047974</td>\n",
       "      <td>11084.583984</td>\n",
       "      <td>0.878906</td>\n",
       "      <td>5806.187500</td>\n",
       "      <td>77.696602</td>\n",
       "      <td>0.833562</td>\n",
       "      <td>0.350311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.427849</td>\n",
       "      <td>3.044484</td>\n",
       "      <td>40.866386</td>\n",
       "      <td>4.732732</td>\n",
       "      <td>2.917459</td>\n",
       "      <td>2.974849</td>\n",
       "      <td>11578.666992</td>\n",
       "      <td>1533.535400</td>\n",
       "      <td>11419.485352</td>\n",
       "      <td>0.880827</td>\n",
       "      <td>5922.156250</td>\n",
       "      <td>77.812218</td>\n",
       "      <td>0.833808</td>\n",
       "      <td>0.361035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.620205</td>\n",
       "      <td>3.003658</td>\n",
       "      <td>41.134510</td>\n",
       "      <td>4.776831</td>\n",
       "      <td>2.919800</td>\n",
       "      <td>3.021343</td>\n",
       "      <td>11825.421875</td>\n",
       "      <td>1552.955322</td>\n",
       "      <td>11371.003906</td>\n",
       "      <td>0.892208</td>\n",
       "      <td>5764.377441</td>\n",
       "      <td>78.439964</td>\n",
       "      <td>0.818645</td>\n",
       "      <td>0.347553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.339977</td>\n",
       "      <td>2.930320</td>\n",
       "      <td>41.128422</td>\n",
       "      <td>4.640864</td>\n",
       "      <td>2.910113</td>\n",
       "      <td>3.063572</td>\n",
       "      <td>13030.048828</td>\n",
       "      <td>1591.686035</td>\n",
       "      <td>11816.966797</td>\n",
       "      <td>0.885492</td>\n",
       "      <td>5677.535156</td>\n",
       "      <td>77.890305</td>\n",
       "      <td>0.804707</td>\n",
       "      <td>0.363450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.249527</td>\n",
       "      <td>2.929391</td>\n",
       "      <td>41.053093</td>\n",
       "      <td>4.602085</td>\n",
       "      <td>2.922823</td>\n",
       "      <td>3.042693</td>\n",
       "      <td>12996.541016</td>\n",
       "      <td>1595.761719</td>\n",
       "      <td>11993.082031</td>\n",
       "      <td>0.874112</td>\n",
       "      <td>5805.371582</td>\n",
       "      <td>76.912636</td>\n",
       "      <td>0.805229</td>\n",
       "      <td>0.379652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>49.303017</td>\n",
       "      <td>2.995013</td>\n",
       "      <td>42.381237</td>\n",
       "      <td>4.813211</td>\n",
       "      <td>3.048095</td>\n",
       "      <td>2.918695</td>\n",
       "      <td>11023.661133</td>\n",
       "      <td>1457.613525</td>\n",
       "      <td>10865.768555</td>\n",
       "      <td>0.862400</td>\n",
       "      <td>5411.801270</td>\n",
       "      <td>78.952301</td>\n",
       "      <td>0.802648</td>\n",
       "      <td>0.332380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>50.129490</td>\n",
       "      <td>2.989905</td>\n",
       "      <td>40.635414</td>\n",
       "      <td>4.727664</td>\n",
       "      <td>2.871826</td>\n",
       "      <td>3.039865</td>\n",
       "      <td>12605.060547</td>\n",
       "      <td>1562.877441</td>\n",
       "      <td>11536.345703</td>\n",
       "      <td>0.891549</td>\n",
       "      <td>5794.744629</td>\n",
       "      <td>78.274872</td>\n",
       "      <td>0.820156</td>\n",
       "      <td>0.363032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>49.805061</td>\n",
       "      <td>2.939523</td>\n",
       "      <td>40.882080</td>\n",
       "      <td>4.729547</td>\n",
       "      <td>2.880733</td>\n",
       "      <td>3.103799</td>\n",
       "      <td>12767.844727</td>\n",
       "      <td>1587.812012</td>\n",
       "      <td>11738.684570</td>\n",
       "      <td>0.903886</td>\n",
       "      <td>5788.503418</td>\n",
       "      <td>79.434303</td>\n",
       "      <td>0.810623</td>\n",
       "      <td>0.367031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>49.951023</td>\n",
       "      <td>3.036306</td>\n",
       "      <td>40.479431</td>\n",
       "      <td>4.715777</td>\n",
       "      <td>2.871674</td>\n",
       "      <td>2.993943</td>\n",
       "      <td>12212.618164</td>\n",
       "      <td>1537.057495</td>\n",
       "      <td>11434.994141</td>\n",
       "      <td>0.884678</td>\n",
       "      <td>5867.729492</td>\n",
       "      <td>78.019394</td>\n",
       "      <td>0.834372</td>\n",
       "      <td>0.364967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>49.751987</td>\n",
       "      <td>2.994274</td>\n",
       "      <td>41.111763</td>\n",
       "      <td>4.561594</td>\n",
       "      <td>2.924921</td>\n",
       "      <td>2.994667</td>\n",
       "      <td>12374.107422</td>\n",
       "      <td>1530.863403</td>\n",
       "      <td>11737.943359</td>\n",
       "      <td>0.875124</td>\n",
       "      <td>5740.002441</td>\n",
       "      <td>78.739830</td>\n",
       "      <td>0.832527</td>\n",
       "      <td>0.371492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_age  dependent_count  months_on_book  total_relationship_count  \\\n",
       "0      49.630863         3.080832       41.161160                  4.759431   \n",
       "1      49.427849         3.044484       40.866386                  4.732732   \n",
       "2      49.620205         3.003658       41.134510                  4.776831   \n",
       "3      50.339977         2.930320       41.128422                  4.640864   \n",
       "4      50.249527         2.929391       41.053093                  4.602085   \n",
       "..           ...              ...             ...                       ...   \n",
       "95     49.303017         2.995013       42.381237                  4.813211   \n",
       "96     50.129490         2.989905       40.635414                  4.727664   \n",
       "97     49.805061         2.939523       40.882080                  4.729547   \n",
       "98     49.951023         3.036306       40.479431                  4.715777   \n",
       "99     49.751987         2.994274       41.111763                  4.561594   \n",
       "\n",
       "    months_inactive_12_mon  contacts_count_12_mon  credit_limit  \\\n",
       "0                 2.916995               2.985534  11411.318359   \n",
       "1                 2.917459               2.974849  11578.666992   \n",
       "2                 2.919800               3.021343  11825.421875   \n",
       "3                 2.910113               3.063572  13030.048828   \n",
       "4                 2.922823               3.042693  12996.541016   \n",
       "..                     ...                    ...           ...   \n",
       "95                3.048095               2.918695  11023.661133   \n",
       "96                2.871826               3.039865  12605.060547   \n",
       "97                2.880733               3.103799  12767.844727   \n",
       "98                2.871674               2.993943  12212.618164   \n",
       "99                2.924921               2.994667  12374.107422   \n",
       "\n",
       "    total_revolving_bal  avg_open_to_buy  total_amt_chng_q4_q1  \\\n",
       "0           1534.047974     11084.583984              0.878906   \n",
       "1           1533.535400     11419.485352              0.880827   \n",
       "2           1552.955322     11371.003906              0.892208   \n",
       "3           1591.686035     11816.966797              0.885492   \n",
       "4           1595.761719     11993.082031              0.874112   \n",
       "..                  ...              ...                   ...   \n",
       "95          1457.613525     10865.768555              0.862400   \n",
       "96          1562.877441     11536.345703              0.891549   \n",
       "97          1587.812012     11738.684570              0.903886   \n",
       "98          1537.057495     11434.994141              0.884678   \n",
       "99          1530.863403     11737.943359              0.875124   \n",
       "\n",
       "    total_trans_amt  total_trans_ct  total_ct_chng_q4_q1  \\\n",
       "0       5806.187500       77.696602             0.833562   \n",
       "1       5922.156250       77.812218             0.833808   \n",
       "2       5764.377441       78.439964             0.818645   \n",
       "3       5677.535156       77.890305             0.804707   \n",
       "4       5805.371582       76.912636             0.805229   \n",
       "..              ...             ...                  ...   \n",
       "95      5411.801270       78.952301             0.802648   \n",
       "96      5794.744629       78.274872             0.820156   \n",
       "97      5788.503418       79.434303             0.810623   \n",
       "98      5867.729492       78.019394             0.834372   \n",
       "99      5740.002441       78.739830             0.832527   \n",
       "\n",
       "    avg_utilization_ratio  \n",
       "0                0.350311  \n",
       "1                0.361035  \n",
       "2                0.347553  \n",
       "3                0.363450  \n",
       "4                0.379652  \n",
       "..                    ...  \n",
       "95               0.332380  \n",
       "96               0.363032  \n",
       "97               0.367031  \n",
       "98               0.364967  \n",
       "99               0.371492  \n",
       "\n",
       "[100 rows x 14 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(inverse_scale_data(synthetic_data,scaler),columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb935199-16f3-4cc8-8621-6cf05ca0e3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
