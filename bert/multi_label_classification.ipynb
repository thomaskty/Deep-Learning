{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9518ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pandas as pd \n",
    "import torch \n",
    "import numpy as np \n",
    "from sklearn import metrics \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data import RandomSampler,SequentialSampler\n",
    "from transformers import BertTokenizer,BertModel,BertConfig\n",
    "from torch import cuda \n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfca5b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "186a433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('jigsaw_toxic_comment_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49210bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffec7569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c9639a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee3c668a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text                list\n",
       "0  Explanation\\nWhy the edits made under my usern...  [0, 0, 0, 0, 0, 0]\n",
       "1  D'aww! He matches this background colour I'm s...  [0, 0, 0, 0, 0, 0]\n",
       "2  Hey man, I'm really not trying to edit war. It...  [0, 0, 0, 0, 0, 0]\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...  [0, 0, 0, 0, 0, 0]\n",
       "4  You, sir, are my hero. Any chance you remember...  [0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['list'] = df[df.columns[2:]].values.tolist()\n",
    "new_df = df[['comment_text', 'list']].copy()\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4bcf2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.loc[0]['list']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f200579e",
   "metadata": {},
   "source": [
    "Dataloader that will feed the data in batches to the neural network for suitable training and processing. Dataset and Dataloader are constructs of the PyTorch library for defining and controlling the data pre-processing and its passage to neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48f99927",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "TRAIN_BATCH_SIZE = 64 \n",
    "VALID_BATCH_SIZE = 4 \n",
    "EPOCHS = 1 \n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a419b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,dataframe,tokenizer,max_len):\n",
    "        self.tokenizer = tokenizer \n",
    "        self.data = dataframe \n",
    "        self.comment_text = dataframe.comment_text \n",
    "        self.targets = self.data.list \n",
    "        self.max_len = max_len \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.comment_text)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        comment_text = str(self.comment_text[index])\n",
    "        comment_text = \" \".join(comment_text.split())\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            comment_text,\n",
    "            None,\n",
    "            add_special_tokens = True,\n",
    "            max_length = self.max_len,\n",
    "            pad_to_max_length = True,\n",
    "            return_token_type_ids = True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "        \n",
    "        return {\n",
    "            'ids':torch.tensor(ids,dtype=torch.long),\n",
    "            'mask':torch.tensor(mask,dtype=torch.long),\n",
    "            'token_type_ids':torch.tensor(token_type_ids,dtype=torch.long),\n",
    "            'target':torch.tensor(self.targets[index],dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f4e0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = str(df['comment_text'][0]).split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bbc4d9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Explanation\\nWhy', 'the', 'edits', 'made', 'under', 'my', 'username', 'Hardcore', 'Metallica', 'Fan', 'were', 'reverted?', 'They', \"weren't\", 'vandalisms,', 'just', 'closure', 'on', 'some', 'GAs', 'after', 'I', 'voted', 'at', 'New', 'York', 'Dolls', 'FAC.', 'And', 'please', \"don't\", 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', \"I'm\", 'retired', 'now.89.205.38.27']\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34115a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9be562f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 100, 1996, 100, 2081, 2104, 2026, 100, 100, 100, 100, 2020, 100, 100, 100, 100, 2074, 8503, 2006, 2070, 100, 2044, 100, 5444, 2012, 100, 100, 100, 100, 100, 3531, 100, 6366, 1996, 23561, 2013, 1996, 2831, 3931, 2144, 100, 3394, 100, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "003c96bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode_plus(text)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15cad7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 100, 1996, 100, 2081, 2104, 2026, 100, 100, 100, 100, 2020, 100, 100, 100, 100, 2074, 8503, 2006, 2070, 100, 2044, 100, 5444, 2012, 100, 100, 100, 100, 100, 3531, 100, 6366, 1996, 23561, 2013, 1996, 2831, 3931, 2144, 100, 3394, 100, 102]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c8490d",
   "metadata": {},
   "source": [
    "* token_type_ids: This list indicates to which segment each token belongs. \n",
    "* input_ids: This is a list of integers representing the tokenized version of the input text.\n",
    "* attention_mask: This list of binary values (0 or 1) indicates which tokens should be attended to (1) and which should be ignored (0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c1acaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.03\n",
    "test_size = 0.01\n",
    "train_dataset = new_df.sample(frac = train_size,random_state = 200)\n",
    "test_dataset = new_df.drop(train_dataset.index).reset_index(drop = True)\n",
    "train_dataset = train_dataset.reset_index(drop = True)\n",
    "test_dataset = new_df.sample(frac = 0.01,random_state = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38ce0d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset :(159571, 2)\n",
      "Train dataset :(4787, 2)\n",
      "Test dataset :(1596, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Full dataset :{}'.format(new_df.shape))\n",
    "print('Train dataset :{}'.format(train_dataset.shape))\n",
    "print('Test dataset :{}'.format(test_dataset.shape))\n",
    "\n",
    "training_set = CustomDataset(train_dataset,tokenizer,MAX_LEN)\n",
    "testing_set = CustomDataset(test_dataset,tokenizer,MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7bef45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4787"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b4fcf20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids torch.Size([50])\n",
      "mask torch.Size([50])\n",
      "token_type_ids torch.Size([50])\n",
      "target torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "sample_index = 39\n",
    "for i in training_set[sample_index].keys():\n",
    "    print(i,training_set[sample_index][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57ce815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'batch_size':TRAIN_BATCH_SIZE,\n",
    "    'shuffle':True,\n",
    "    'num_workers':0\n",
    "}\n",
    "test_params = {\n",
    "    'batch_size':VALID_BATCH_SIZE,\n",
    "    'shuffle':True,\n",
    "    'num_workers':0\n",
    "}\n",
    "training_loader = DataLoader(training_set,**train_params)\n",
    "testing_loader = DataLoader(testing_set,**test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1173cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass,self).__init__()\n",
    "        self.bert_layer = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout_layer = torch.nn.Dropout(0.3)\n",
    "        self.linear_layer = torch.nn.Linear(768,6)\n",
    "        \n",
    "    def forward(self,ids,mask,token_type_ids):\n",
    "        _,output = self.bert_layer(\n",
    "            ids,\n",
    "            attention_mask = mask,\n",
    "            token_type_ids = token_type_ids,\n",
    "            return_dict = False\n",
    "        )\n",
    "        output_b = self.dropout_layer(output)\n",
    "        output = self.linear_layer(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70b5e11d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (bert_layer): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout_layer): Dropout(p=0.3, inplace=False)\n",
       "  (linear_layer): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da611696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs,targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa872001",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    params = model.parameters(),\n",
    "    lr = LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb548146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _,data in enumerate(training_loader,0):\n",
    "        ids = data['ids'].to(device,dtype=torch.long)\n",
    "        mask = data['mask'].to(device,dtype=torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device,dtype=torch.long)\n",
    "        targets = data['target'].to(device)\n",
    "        \n",
    "        outputs = model(ids,mask,token_type_ids)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs,targets)\n",
    "        \n",
    "        print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae13ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a22a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation():\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "749620ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "fin_targets = []\n",
    "fin_outputs = []\n",
    "with torch.no_grad():\n",
    "    for _,data in enumerate(training_loader,0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['target'].to(device, dtype = torch.float)\n",
    "        outputs = model(ids,mask,token_type_ids)\n",
    "        fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "        fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in fin_outputs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf7db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for outputs,targets in zip(fin_outputs,fin_targets):\n",
    "    outputs = np.array(outputs) >= 0.5\n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98576421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
