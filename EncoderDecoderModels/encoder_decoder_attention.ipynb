{"cells":[{"cell_type":"code","source":["from google.colab import drive \n","drive.mount('/content/drive/',force_remount = True) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u8sWg04dTuJR","executionInfo":{"status":"ok","timestamp":1674152199589,"user_tz":-330,"elapsed":30197,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}},"outputId":"8691b87e-c206-413c-fe20-e96c6adce070"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["from io import open \n","import unicodedata\n","import string\n","import re\n","import random\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"ThKMXPmPUGsS","executionInfo":{"status":"ok","timestamp":1674152211182,"user_tz":-330,"elapsed":2801,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os \n","os.chdir('/content/drive/MyDrive/DeepLearningPytorch')"],"metadata":{"id":"xEzDZYgLUPmw","executionInfo":{"status":"ok","timestamp":1674152214732,"user_tz":-330,"elapsed":5,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["SOS_token = 0\n","EOS_token = 1\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1\n","            \n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    return s\n","\n","def readLangs(lang1, lang2, reverse=False):\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    with open('english_german_translation.txt','r',encoding = 'utf-8') as text_file:\n","        lines = text_file.readlines()\n","    # Split every line into pairs and normalize\n","    pairs = [\n","        [normalizeString(s).replace('.','').strip() for s in l.split('\\t')][0:2] \n","        for l in lines]\n","    \n","    # Reverse pairs, make Lang instances\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","        input_lang = Lang(lang2)\n","        output_lang = Lang(lang1)\n","    else:\n","        input_lang = Lang(lang1)\n","        output_lang = Lang(lang2)\n","\n","    return input_lang, output_lang, pairs\n","\n","def prepareData(lang1, lang2, reverse=False):\n","    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    pairs = [i for i in pairs if \n","             len(i[0].split(' '))>3 and \n","             len(i[0].split(' '))<6 and \n","             len(i[1].split(' '))<6  and \n","             len(i[1].split(' '))>3]\n","    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    return input_lang, output_lang, pairs\n","\n","\n","input_lang, output_lang, pairs = prepareData('eng', 'ger', True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jqfh6M1zUGPZ","executionInfo":{"status":"ok","timestamp":1674152232440,"user_tz":-330,"elapsed":15457,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}},"outputId":"29d6d8ff-3805-4392-94e1-31e1b309f07b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading lines...\n","Read 255817 sentence pairs\n","Trimmed to 52448 sentence pairs\n","Counting words...\n","Counted words:\n","ger 12661\n","eng 7980\n"]}]},{"cell_type":"code","source":["max_length_input = max([len(pairs[i][0].split()) for i in range(len(pairs))])\n","max_length_target = max([len(pairs[i][1].split()) for i in range(len(pairs))])\n","max_length_input,max_length_target"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"klws50E5Uvla","executionInfo":{"status":"ok","timestamp":1674152244737,"user_tz":-330,"elapsed":3,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}},"outputId":"e1a0d45e-c414-4ab6-ea11-1f8db179f402"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5, 5)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["pairs[10:19]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fc1ft-gbVMtP","executionInfo":{"status":"ok","timestamp":1674152246907,"user_tz":-330,"elapsed":7,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}},"outputId":"a140e13f-fbfa-4acb-94f6-93fc066c49cf"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['bin ich zu spat ?', 'am i late ?'],\n"," ['kann ich essen ?', 'can i eat ?'],\n"," ['konnen wir gehen ?', 'can we go ?'],\n"," ['habe ich gewonnen ?', 'did i win ?'],\n"," ['wie ist die lage ?', 'how is it ?'],\n"," ['ich liebe es !', 'i love it !'],\n"," ['ich meine es so !', 'i mean it !'],\n"," ['ich meine es ernst !', 'i mean it !'],\n"," ['ich wurde es tun', 'i d do it']]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","def tensorFromSentence_input(lang, sentence,max_length_input):\n","    indexes = indexesFromSentence(lang, sentence)\n","    while len(indexes)<max_length_input+1:\n","        indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","def tensorFromSentence_output(lang, sentence,max_length_target):\n","    indexes = indexesFromSentence(lang, sentence)\n","    while len(indexes)<max_length_target+1:\n","        indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence_input(input_lang, pair[0],max_length_input)\n","    target_tensor = tensorFromSentence_output(output_lang, pair[1],max_length_target)\n","    return (input_tensor, target_tensor)\n","\n","# creating all input/output sentence pairs \n","training_pairs = [tensorsFromPair(i) for i in pairs]\n","max_seq_len_input = max([len(training_pairs[i][0]) for i in range(len(training_pairs))])\n","max_seq_len_target = max([len(training_pairs[i][1]) for i in range(len(training_pairs))])"],"metadata":{"id":"4OsBmmTAVSnv","executionInfo":{"status":"ok","timestamp":1674152255794,"user_tz":-330,"elapsed":6863,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["training_pairs[4942]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Dekk2saVUqh","executionInfo":{"status":"ok","timestamp":1674152256622,"user_tz":-330,"elapsed":8,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}},"outputId":"8434c9d4-44cb-46dd-fedd-60874ea06b57"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 48],\n","         [ 18],\n","         [ 77],\n","         [133],\n","         [  1],\n","         [  1]], device='cuda:0'), tensor([[102],\n","         [329],\n","         [ 72],\n","         [ 97],\n","         [  1],\n","         [  1]], device='cuda:0'))"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["class dataset(Dataset):\n","    def __init__(self,training_pairs):\n","        self.training_pairs = training_pairs\n","  \n","    def __getitem__(self,idx):\n","        return self.training_pairs[idx][0],self.training_pairs[idx][1]\n","    def __len__(self):\n","        return len(self.training_pairs)\n","    \n","trainset = dataset(training_pairs)\n","train_loader = DataLoader(trainset,batch_size=64,shuffle=False)"],"metadata":{"id":"lqkRzcbsVUm-","executionInfo":{"status":"ok","timestamp":1674152337213,"user_tz":-330,"elapsed":600,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"id":"xPe1CzYTTrvD","executionInfo":{"status":"ok","timestamp":1674152339972,"user_tz":-330,"elapsed":6,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}}},"outputs":[],"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size,embedding_dim):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, embedding_dim)\n","        self.rnn = nn.RNN(embedding_dim, hidden_size,batch_first=  True)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).squeeze()\n","        output = embedded\n","        output, hidden = self.rnn(output, hidden)\n","        return output, hidden\n","\n","    def initHidden(self,batch_size):\n","        return torch.zeros(1, batch_size, self.hidden_size, device=device)"]},{"cell_type":"code","source":["class AttentionDecoderRNN(nn.Module):\n","    def __init__(self,output_size,hidden_size,embedding_dim,input_seq_max_length,target_seq_max):\n","        super(AttentionDecoderRNN,self).__init__() \n","        self.output_size = output_size \n","        self.input_seq_max_length = input_seq_max_length \n","        self.embedding = nn.Embedding(output_size,embedding_dim) \n","        self.attention_weights = nn.Linear(hidden_size+embedding_dim,input_seq_max_length)\n","        self.attention_combine = nn.Linear(hidden_size+embedding_dim,hidden_size) \n","        self.out = nn.Linear(hidden_size,output_size) \n","        self.rnn = nn.GRU(hidden_size,hidden_size,batch_first = True) \n","        self.softmax = nn.LogSoftmax(dim=-1)\n","\n","    def forward(self,x,hidden,encoder_outputs):\n","        embedded = self.embedding(x) # batch,1,emb_dim\n","        embedded = embedded.permute(1,0,2)\n","\n","        emb_hid_cat = torch.cat([embedded.permute,hidden],dim =2)  # 1,batch,emb_dim+hid_dim\n","        attention_weights = self.attention_weights(emb_hid_cat) # 1,batch,input_seq_max_length \n","        attention_weights = attention_weights.permute(1,0,2)\n","        context_vector = torch.bmm(attention_weights,encoder_outputs)\n","\n","        # combine attn_applied and embedded\n","        context_vector = context_vector.permute(1,0,2)\n","        combine_layer_input = torch.cat([context_vector,embedded],dim = 2)\n","        combine_out = self.attention_combine(combine_layer_input)\n","        combine_out = combine_out.permute(1,0,2) \n","        rnn_out,rnn_hid = self.rnn(combine_out,hidden)\n","        final_output= self.softmax(self.out(rnn_out))\n","        return final_output,rnn_hid,attention_weights"],"metadata":{"id":"rzzEXEjhaXlW","executionInfo":{"status":"ok","timestamp":1674152342027,"user_tz":-330,"elapsed":4,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class seq2seq(nn.Module):\n","    def __init__(self,encoder,decoder,teacher_force_ratio = 0.5):\n","        super(seq2seq,self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder \n","        self.teacher_force_ratio = teacher_force_ratio \n","    def forward(self,source,target):\n","        # source shape : (2,7,1) : batch_size,source_sequence_length,1\n","        # target shape : (2,7,1) : batch_size,target_seq_length,1\n","        \n","        target_seq_length = target.shape[1]\n","        source_seq_length = source.shape[1] \n","        batch_size = source.shape[0] \n","        no_output_tokens = self.decoder.output_size \n","        \n","        encoder_hidden = self.encoder.initHidden(batch_size)\n","        encoder_outputs,encoder_hidden = self.encoder(source,encoder_hidden) \n","        \n","        x = source[:,source_seq_length-1,:]\n","        outputs = torch.zeros(target_seq_length,batch_size,1,no_output_tokens)\n","        for timestep in range(0,target_seq_length):\n","            decoder_output,decoder_hidden,attention_weights = self.decoder(x,encoder_hidden,encoder_outputs)\n","            # decoder_output shape : (batch_size,1,no_output_tokens)\n","            outputs[timestep,:,:,:] = decoder_output\n","            best_guess = decoder_output.argmax(2)\n","            x = target[:,timestep,:] if random.random()<self.teacher_force_ratio else best_guess\n","        return outputs "],"metadata":{"id":"_UhUG3FKE5_1","executionInfo":{"status":"ok","timestamp":1674152342955,"user_tz":-330,"elapsed":14,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(101)\n","num_epochs = 30  \n","learning_rate = 0.001 \n","batch_size = 256\n","embedding_dim = 256 \n","hidden_size = 128 \n","learning_rate = 0.001 \n","encoder = EncoderRNN(input_lang.n_words, hidden_size,embedding_dim)\n","decoder = AttentionDecoderRNN(output_lang.n_words,hidden_size,embedding_dim,max_seq_len_input,max_seq_len_target)\n","criterion = nn.CrossEntropyLoss(ignore_index=EOS_token)\n","model = seq2seq(encoder,decoder).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","for epoch in range(num_epochs):\n","    epoch_loss = 0 \n","    model.train() \n","    for batch_idx,batch in enumerate(train_loader):\n","        source = batch[0].to(device)\n","        target = batch[1].to(device)\n","        batch_output = model(source,target).to(device)\n","        batch_output = batch_output.squeeze(2)\n","        batch_output = batch_output.permute(1,0,2)\n","        first_dim = batch_output.shape[0]* batch_output.shape[1] \n","        batch_output = batch_output.reshape(first_dim,decoder.output_size)\n","        target = target.squeeze(2)\n","        target = target.reshape(-1) \n","\n","        optimizer.zero_grad() \n","        loss = criterion(batch_output,target)\n","        \n","        epoch_loss+=loss.item() \n","        \n","        loss.backward() \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","        optimizer.step() \n","    print(f'epoch = {epoch} - loss = {epoch_loss}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S-RqKh83E58S","executionInfo":{"status":"ok","timestamp":1674153259760,"user_tz":-330,"elapsed":916817,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}},"outputId":"1c613780-5609-4196-fb80-5676fce5842f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch = 0 - loss = 3908.020450592041\n","epoch = 1 - loss = 2798.905596256256\n","epoch = 2 - loss = 2334.059930205345\n","epoch = 3 - loss = 2030.199009358883\n","epoch = 4 - loss = 1808.6228539943695\n","epoch = 5 - loss = 1635.8568942546844\n","epoch = 6 - loss = 1490.5327734947205\n","epoch = 7 - loss = 1380.2000402212143\n","epoch = 8 - loss = 1293.107670456171\n","epoch = 9 - loss = 1217.4251962602139\n","epoch = 10 - loss = 1146.8003385961056\n","epoch = 11 - loss = 1103.887454777956\n","epoch = 12 - loss = 1046.780684441328\n","epoch = 13 - loss = 1015.356229454279\n","epoch = 14 - loss = 973.1371029317379\n","epoch = 15 - loss = 951.5205255448818\n","epoch = 16 - loss = 919.0105409771204\n","epoch = 17 - loss = 894.6627846509218\n","epoch = 18 - loss = 871.1435580253601\n","epoch = 19 - loss = 842.2487032711506\n","epoch = 20 - loss = 837.5911224484444\n","epoch = 21 - loss = 820.9534720927477\n","epoch = 22 - loss = 801.0231860727072\n","epoch = 23 - loss = 785.9413891583681\n","epoch = 24 - loss = 782.8735755085945\n","epoch = 25 - loss = 772.8325341790915\n","epoch = 26 - loss = 765.7441130876541\n","epoch = 27 - loss = 740.3402888476849\n","epoch = 28 - loss = 740.9405363947153\n","epoch = 29 - loss = 742.6407731026411\n"]}]},{"cell_type":"code","source":["def evaluate(encoder,decoder,test_pairs,max_length):\n","    with torch.no_grad():\n","        testing_pairs = [tensorsFromPair(i) for i in test_pairs]\n","        batch_size = len(testing_pairs)\n","        testset = dataset(testing_pairs) \n","        test_loader = DataLoader(testset,batch_size,shuffle=False) \n","\n","        for batch_id,batch in enumerate(test_loader):\n","            source = batch[0].to(device)\n","            source_seq_length = source.shape[1] \n","            target = batch[1].to(device)\n","        \n","            encoder_hidden = encoder.initHidden(batch_size).to(device)  # batch size = 1 \n","            encoder_outputs,encoder_hidden = encoder(source,encoder_hidden) \n","            decoded_words = torch.zeros(size = (max_length,batch_size,1))\n","            x = source[:,source_seq_length-1,:]\n","            for timestep in range(0,max_length):\n","                decoder_output,decoder_hidden,attention_weights = decoder(x,encoder_hidden,encoder_outputs)\n","                # decoder_output shape : (batch_size,1,no_output_tokens)\n","                best_guess = decoder_output.argmax(2)\n","                x = best_guess\n","                decoded_words[timestep,:,:] = x\n","            out_v1 = decoded_words.permute(1,0,2).squeeze(2).tolist() \n","            final_predictions = [' '.join([output_lang.index2word[int(i)] for i in out]) for out in out_v1]\n","            \n","            for i in range(len(test_pairs)):\n","                print(f'input -> {test_pairs[i][0]}')\n","                print(f'actual -> {test_pairs[i][1]}')\n","                print(f'predicted -> {final_predictions[i]}')\n","                print('----------------------------------------')"],"metadata":{"id":"eIyuG_-RE55s","executionInfo":{"status":"ok","timestamp":1674156193895,"user_tz":-330,"elapsed":7,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["evaluate(encoder,decoder,pairs[585:587],4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LcuLUDINWuHc","executionInfo":{"status":"ok","timestamp":1674156259495,"user_tz":-330,"elapsed":6,"user":{"displayName":"Thomaskutty Reji","userId":"02052053620409751240"}},"outputId":"a30c2750-393e-4c99-b119-f259f242681e"},"execution_count":125,"outputs":[{"output_type":"stream","name":"stdout","text":["input -> ich war ein idiot\n","actual -> i was a fool\n","predicted -> i was an idiot\n","----------------------------------------\n","input -> ich war nicht verruckt\n","actual -> i wasn t mad\n","predicted -> i wasn t crazy\n","----------------------------------------\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cc9tmpLzT-PP"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"ca9c90c9b299e3c35d28bc96236d8f2c0bd3d51256cb5ad616950692d4a1a879"}},"colab":{"provenance":[],"toc_visible":true},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}