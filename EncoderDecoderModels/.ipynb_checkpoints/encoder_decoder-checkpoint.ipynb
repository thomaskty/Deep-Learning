{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24237,
     "status": "ok",
     "timestamp": 1674111551190,
     "user": {
      "displayName": "Thomaskutty Reji",
      "userId": "02052053620409751240"
     },
     "user_tz": -330
    },
    "id": "qhU-z8tPk5Zb",
    "outputId": "fd0def3c-d5fb-448b-86b7-f1d33875395f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2JDnGmA3k7e6"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "# os.chdir('/content/drive/MyDrive/DeepLearningPytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3592,
     "status": "ok",
     "timestamp": 1674100320491,
     "user": {
      "displayName": "Thomaskutty Reji",
      "userId": "02052053620409751240"
     },
     "user_tz": -330
    },
    "id": "05bD-jXDPlJv",
    "outputId": "26d69627-1b16-4921-d46f-5e322a76bb9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cpu\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13994,
     "status": "ok",
     "timestamp": 1674100418401,
     "user": {
      "displayName": "Thomaskutty Reji",
      "userId": "02052053620409751240"
     },
     "user_tz": -330
    },
    "id": "nSg76ewdPlJ2",
    "outputId": "6379aff5-c108-4d08-c318-9acd478c5257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    }
   ],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    with open('dataset/english_german_translation.txt','r',encoding = 'utf-8') as text_file:\n",
    "        lines = text_file.readlines()\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [\n",
    "        [normalizeString(s).replace('.','').strip() for s in l.split('\\t')][0:2] \n",
    "        for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = [i for i in pairs if \n",
    "             len(i[0].split(' '))>0 and \n",
    "             len(i[0].split(' '))<5 and \n",
    "             len(i[1].split(' '))<5  and \n",
    "             len(i[1].split(' '))>0]\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'ger', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxA67g4BPlJ9"
   },
   "outputs": [],
   "source": [
    "max_length_input = max([len(pairs[i][0].split()) for i in range(len(pairs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zveUxcVVPlJ-"
   },
   "outputs": [],
   "source": [
    "max_length_target = max([len(pairs[i][1].split()) for i in range(len(pairs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1674057153113,
     "user": {
      "displayName": "Thomaskutty Reji",
      "userId": "02052053620409751240"
     },
     "user_tz": -330
    },
    "id": "Q4_KsE_5PlJ-",
    "outputId": "9ac8a842-f953-4dbb-c067-c2d9460f4c1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_input,max_length_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1674057153896,
     "user": {
      "displayName": "Thomaskutty Reji",
      "userId": "02052053620409751240"
     },
     "user_tz": -330
    },
    "id": "y4mh6MU4ZTkQ",
    "outputId": "2cf6c1e9-40c3-4ffa-f9ab-42666de0c9a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32794"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1674057155810,
     "user": {
      "displayName": "Thomaskutty Reji",
      "userId": "02052053620409751240"
     },
     "user_tz": -330
    },
    "id": "-mgVYnxSPlJ_",
    "outputId": "91901557-f6f1-437f-e40f-155410cffbb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['zu hulf !', 'help !'],\n",
       " ['bleib !', 'stay'],\n",
       " ['stopp !', 'stop !'],\n",
       " ['anhalten !', 'stop !'],\n",
       " ['warte !', 'wait !'],\n",
       " ['warte', 'wait'],\n",
       " ['fang an', 'begin'],\n",
       " ['mache es !', 'do it'],\n",
       " ['tue es', 'do it']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[10:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHB9NYK-PlKA"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence_input(lang, sentence,max_length_input):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    while len(indexes)<max_length_input+1:\n",
    "        indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorFromSentence_output(lang, sentence,max_length_target):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    while len(indexes)<max_length_target+1:\n",
    "        indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence_input(input_lang, pair[0],max_length_input)\n",
    "    target_tensor = tensorFromSentence_output(output_lang, pair[1],max_length_target)\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "# creating all input/output sentence pairs \n",
    "training_pairs = [tensorsFromPair(i) for i in pairs]\n",
    "max_seq_len_input = max([len(training_pairs[i][0]) for i in range(len(training_pairs))])\n",
    "max_seq_len_target = max([len(training_pairs[i][1]) for i in range(len(training_pairs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 456,
     "status": "ok",
     "timestamp": 1674057281636,
     "user": {
      "displayName": "Thomaskutty Reji",
      "userId": "02052053620409751240"
     },
     "user_tz": -330
    },
    "id": "qWPL89Lik0cd",
    "outputId": "6f6152fc-66df-432c-8129-cdf14b75813f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len_input,max_seq_len_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1674057283240,
     "user": {
      "displayName": "Thomaskutty Reji",
      "userId": "02052053620409751240"
     },
     "user_tz": -330
    },
    "id": "NnJ9HqQPk0ce",
    "outputId": "7a63225e-2f83-4def-de37-73a8f4783b2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 267],\n",
       "         [ 767],\n",
       "         [2110],\n",
       "         [   1],\n",
       "         [   1]], device='cuda:0'), tensor([[122],\n",
       "         [251],\n",
       "         [590],\n",
       "         [  1],\n",
       "         [  1]], device='cuda:0'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pairs[4942]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lfMVR4KvPlKC"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self,training_pairs):\n",
    "        self.training_pairs = training_pairs\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        return self.training_pairs[idx][0],self.training_pairs[idx][1]\n",
    "    def __len__(self):\n",
    "        return len(self.training_pairs)\n",
    "    \n",
    "trainset = dataset(training_pairs)\n",
    "train_loader = DataLoader(trainset,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gY7CUvnaPlKD"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size,batch_first=  True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).squeeze()\n",
    "        output = embedded\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size,dropout_p =0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.RNN(hidden_size, hidden_size,batch_first = True) \n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        self.dropout_p = dropout_p\n",
    "        self.output_size = output_size \n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output)) \n",
    "        return output, hidden\n",
    "\n",
    "class seq2seq(nn.Module):\n",
    "    def __init__(self,encoder,decoder,teacher_force_ratio = 0.5):\n",
    "        super(seq2seq,self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder \n",
    "        self.teacher_force_ratio = teacher_force_ratio \n",
    "    def forward(self,source,target):\n",
    "        # source shape : (2,7,1) : batch_size,source_sequence_length,1\n",
    "        # target shape : (2,7,1) : batch_size,target_seq_length,1\n",
    "        \n",
    "        target_seq_length = target.shape[1]\n",
    "        source_seq_length = source.shape[1] \n",
    "        batch_size = source.shape[0] \n",
    "        no_output_tokens = self.decoder.output_size \n",
    "        \n",
    "        encoder_hidden = self.encoder.initHidden(batch_size)\n",
    "        encoder_output,encoder_hidden = self.encoder(source,encoder_hidden) \n",
    "        \n",
    "        x = source[:,source_seq_length-1,:]\n",
    "        outputs = torch.zeros(target_seq_length,batch_size,1,no_output_tokens)\n",
    "        for timestep in range(0,target_seq_length):\n",
    "            decoder_output,decoder_hidden = self.decoder(x,encoder_hidden) \n",
    "            # decoder_output shape : (batch_size,1,no_output_tokens)\n",
    "            outputs[timestep,:,:,:] = decoder_output\n",
    "            best_guess = decoder_output.argmax(2)\n",
    "            x = target[:,timestep,:] if random.random()<self.teacher_force_ratio else best_guess\n",
    "        return outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWavFPlBPlKE"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder,decoder,sentence,max_length):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence_input(input_lang,sentence,max_length_input)\n",
    "        input_tensor.to(device)\n",
    "        encoder_hidden = encoder.initHidden(1).to(device)  # batch size = 1 \n",
    "        encoder_hidden = encoder_hidden.squeeze(0)\n",
    "        encoder_output,encoder_hidden = encoder(input_tensor,encoder_hidden)\n",
    "        \n",
    "        decoded_words = []\n",
    "        x = torch.tensor([1]).to(device)\n",
    "        for i in range(1,max_length):\n",
    "            decoder_output,decoder_hidden = decoder(x,encoder_hidden)\n",
    "            # print(decoder_output[0:30])\n",
    "            best_guess = decoder_output.argmax()\n",
    "            if best_guess.item() == EOS_token:\n",
    "                decoded_words.append(output_lang.index2word[EOS_token]) \n",
    "                break\n",
    "            else:\n",
    "                x = best_guess.unsqueeze(0)\n",
    "                decoded_words.append(output_lang.index2word[best_guess.item()]) \n",
    "                \n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 316854,
     "status": "ok",
     "timestamp": 1674058836395,
     "user": {
      "displayName": "Thomaskutty Reji",
      "userId": "02052053620409751240"
     },
     "user_tz": -330
    },
    "id": "ux8499XiPlKF",
    "outputId": "b3724996-3e15-4cf8-c0bb-9705a378d80c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 - loss = 3033.336233139038\n",
      "epoch = 1 - loss = 2491.2138266563416\n",
      "epoch = 2 - loss = 2201.1627464294434\n",
      "epoch = 3 - loss = 2004.2172694206238\n",
      "epoch = 4 - loss = 1853.0008175373077\n",
      "epoch = 5 - loss = 1732.7814071178436\n",
      "epoch = 6 - loss = 1625.4103680849075\n",
      "epoch = 7 - loss = 1533.6368206739426\n",
      "epoch = 8 - loss = 1454.7226966619492\n",
      "epoch = 9 - loss = 1386.1648708581924\n",
      "epoch = 10 - loss = 1314.3836826086044\n",
      "epoch = 11 - loss = 1254.6438978910446\n",
      "epoch = 12 - loss = 1193.1509172916412\n",
      "epoch = 13 - loss = 1136.0967282652855\n",
      "epoch = 14 - loss = 1086.2931242585182\n",
      "epoch = 15 - loss = 1041.9201727509499\n",
      "epoch = 16 - loss = 995.9370602965355\n",
      "epoch = 17 - loss = 957.6231452822685\n",
      "epoch = 18 - loss = 907.8323485851288\n",
      "epoch = 19 - loss = 866.4895567297935\n",
      "epoch = 20 - loss = 833.9026212394238\n",
      "epoch = 21 - loss = 796.2531465888023\n",
      "epoch = 22 - loss = 763.0917987525463\n",
      "epoch = 23 - loss = 732.311652213335\n",
      "epoch = 24 - loss = 697.2256072163582\n",
      "epoch = 25 - loss = 668.2914018332958\n",
      "epoch = 26 - loss = 645.0104425251484\n",
      "epoch = 27 - loss = 619.8389047086239\n",
      "epoch = 28 - loss = 598.0341938883066\n",
      "epoch = 29 - loss = 571.5272903740406\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "learning_rate = 0.001 \n",
    "encoder = EncoderRNN(input_lang.n_words,embedding_dim)\n",
    "decoder = DecoderRNN(embedding_dim,output_lang.n_words)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=EOS_token)\n",
    "model = seq2seq(encoder,decoder).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 30  \n",
    "learning_rate = 0.001 \n",
    "batch_size = 256\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0 \n",
    "    model.train() \n",
    "    for batch_idx,batch in enumerate(train_loader):\n",
    "        source = batch[0].to(device)\n",
    "        target = batch[1].to(device)\n",
    "        batch_output = model(source,target).to(device)\n",
    "        batch_output = batch_output.squeeze(2)\n",
    "        batch_output = batch_output.permute(1,0,2)\n",
    "        first_dim = batch_output.shape[0]* batch_output.shape[1] \n",
    "        batch_output = batch_output.reshape(first_dim,decoder.output_size)\n",
    "        target = target.squeeze(2)\n",
    "        target = target.reshape(-1) \n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        loss = criterion(batch_output,target)\n",
    "        \n",
    "        epoch_loss+=loss.item() \n",
    "        \n",
    "        loss.backward() \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step() \n",
    "    print(f'epoch = {epoch} - loss = {epoch_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1674057564566,
     "user": {
      "displayName": "Thomaskutty Reji",
      "userId": "02052053620409751240"
     },
     "user_tz": -330
    },
    "id": "vMDND8nWPlKH",
    "outputId": "98b0bac5-873f-4811-a8b7-d1f26b853247"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scher dich fort !', 'get lost !']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[390]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1674057569337,
     "user": {
      "displayName": "Thomaskutty Reji",
      "userId": "02052053620409751240"
     },
     "user_tz": -330
    },
    "id": "qRqi8hGeXrtk",
    "outputId": "ad2330ce-ebb6-4a0a-b0a9-a5735b7e140b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'get on ! !'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder,decoder,pairs[390][0],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bF1e7pOlmq1S"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder,max_len,n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0],max_len)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1674058946040,
     "user": {
      "displayName": "Thomaskutty Reji",
      "userId": "02052053620409751240"
     },
     "user_tz": -330
    },
    "id": "etIUUA5QnOk4",
    "outputId": "34359cba-315e-4369-f9c3-8cee03399081"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ich muss mich konzentrieren\n",
      "= i need to focus\n",
      "< i accept your australia\n",
      "\n",
      "> niemand wusste das\n",
      "= no one knew that\n",
      "< everyone knew that knows\n",
      "\n",
      "> bist du sportlich ?\n",
      "= are you athletic ?\n",
      "< are you courageous ?\n",
      "\n",
      "> eier sind sehr zerbrechlich\n",
      "= eggs are very fragile\n",
      "< computers are very useful\n",
      "\n",
      "> sie sind alle reizbar\n",
      "= they re all irritable\n",
      "< they re all irritable\n",
      "\n",
      "> tom macht das\n",
      "= tom does that\n",
      "< tom was the compliment\n",
      "\n",
      "> sie sind hasslich\n",
      "= they re ugly\n",
      "< they re attractive attractive\n",
      "\n",
      "> wir gehen\n",
      "= we re going\n",
      "< we re taking pictures\n",
      "\n",
      "> tom ist mikrobiologe\n",
      "= tom is a microbiologist\n",
      "< tom is a microbiologist\n",
      "\n",
      "> ich bin nutzlos\n",
      "= i m useless\n",
      "< i m totally aggressive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder,max_len=5,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0tN4iNDnTaw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca9c90c9b299e3c35d28bc96236d8f2c0bd3d51256cb5ad616950692d4a1a879"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
